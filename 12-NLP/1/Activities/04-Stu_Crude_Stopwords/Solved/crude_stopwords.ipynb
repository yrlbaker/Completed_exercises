{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students Do: Crude Stopwords\n",
    "For this activity, create a function that takes in an article and outputs a list of words that is free of stopwords and any non-letter characters. After looking at the results, define your own list of stopwords to add to the NLTK default set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package reuters to /home/camkirk/nltk_data...\n[nltk_data]   Package reuters is already up-to-date!\n[nltk_data] Downloading package punkt to /home/camkirk/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/camkirk/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from nltk.corpus import reuters, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Code to download corpora\n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crude_article = reuters.raw(fileids=reuters.fileids(categories='crude')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TURKEY CALLS FOR DIALOGUE TO SOLVE DISPUTE\n  Turkey said today its disputes with\n  Greece, including rights on the continental shelf in the Aegean\n  Sea, should be solved through negotiations.\n      A Foreign Ministry statement said the latest crisis between\n  the two NATO members stemmed from the continental shelf dispute\n  and an agreement on this issue would effect the security,\n  economy and other rights of both countries.\n      \"As the issue is basicly political, a solution can only be\n  found by bilateral negotiations,\" the statement said. Greece has\n  repeatedly said the issue was legal and could be solved at the\n  International Court of Justice.\n      The two countries approached armed confrontation last month\n  after Greece announced it planned oil exploration work in the\n  Aegean and Turkey said it would also search for oil.\n      A face-off was averted when Turkey confined its research to\n  territorrial waters. \"The latest crises created an historic\n  opportunity to solve the disputes between the two countries,\"\n  the Foreign Ministry statement said.\n      Turkey's ambassador in Athens, Nazmi Akiman, was due to\n  meet Prime Minister Andreas Papandreou today for the Greek\n  reply to a message sent last week by Turkish Prime Minister\n  Turgut Ozal. The contents of the message were not disclosed.\n  \n\n\n"
     ]
    }
   ],
   "source": [
    "print(crude_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stopwording and regex \n",
    "sw = set(stopwords.words('english'))\n",
    "regex = re.compile(\"[^a-zA-Z ]\")\n",
    "\n",
    "def clean_text(article):\n",
    "    re_clean = regex.sub('', article)\n",
    "    words = word_tokenize(re_clean)\n",
    "    output = [word.lower() for word in words if word.lower() not in sw]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clean_text(crude_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'nazmi', 'economy', 'stemmed', 'agreement', 'could', 'two', 'would', 'political', 'effect', 'turkeys', 'dispute', 'also', 'today', 'faceoff', 'calls', 'greece', 'month', 'including', 'nato', 'armed', 'repeatedly', 'minister', 'sent', 'disclosed', 'continental', 'historic', 'oil', 'planned', 'athens', 'andreas', 'solve', 'announced', 'confined', 'exploration', 'akiman', 'security', 'rights', 'found', 'foreign', 'said', 'reply', 'approached', 'week', 'statement', 'international', 'basicly', 'latest', 'aegean', 'turkish', 'contents', 'sea', 'negotiations', 'last', 'members', 'research', 'turgut', 'disputes', 'bilateral', 'territorrial', 'due', 'court', 'created', 'crises', 'opportunity', 'confrontation', 'solution', 'search', 'justice', 'ministry', 'work', 'legal', 'issue', 'dialogue', 'message', 'ozal', 'papandreou', 'shelf', 'averted', 'meet', 'crisis', 'greek', 'ambassador', 'prime', 'countries', 'waters', 'turkey', 'solved'}\n"
     ]
    }
   ],
   "source": [
    "# print out unique words\n",
    "print(set(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second iteration, with custom stopwords\n",
    "def clean_text(article):\n",
    "    sw = set(stopwords.words('english'))\n",
    "    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "    sw_addons = {'said', 'sent', 'found', 'including', 'today', 'announced', 'week', 'basically', 'also'}\n",
    "    \n",
    "    re_clean = regex.sub('', article)\n",
    "    words = word_tokenize(re_clean)\n",
    "    output = [word.lower() for word in words if word.lower() not in sw.union(sw_addons)]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_addons = {'said', 'sent', 'found', 'including', 'today', 'announced', 'week', 'basically', 'also'}\n",
    "def clean_text(article):\n",
    "\n",
    "    re_clean = regex.sub('', article)\n",
    "    words = word_tokenize(re_clean)\n",
    "    cleaned_text = [word.lower() for word in words if word.lower() not in sw.union(sw_addons)]\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'solve', 'research', 'dialogue', 'turgut', 'disputes', 'confined', 'bilateral', 'territorrial', 'nazmi', 'economy', 'stemmed', 'exploration', 'akiman', 'message', 'due', 'agreement', 'court', 'could', 'athens', 'security', 'rights', 'two', 'created', 'would', 'crises', 'ozal', 'foreign', 'political', 'opportunity', 'papandreou', 'effect', 'reply', 'turkeys', 'approached', 'confrontation', 'dispute', 'shelf', 'solution', 'statement', 'legal', 'international', 'faceoff', 'basicly', 'latest', 'calls', 'greece', 'month', 'armed', 'nato', 'averted', 'search', 'aegean', 'repeatedly', 'justice', 'meet', 'minister', 'disclosed', 'crisis', 'turkish', 'ministry', 'continental', 'contents', 'greek', 'sea', 'work', 'ambassador', 'historic', 'negotiations', 'oil', 'prime', 'countries', 'planned', 'waters', 'turkey', 'last', 'solved', 'issue', 'members', 'andreas'}\n"
     ]
    }
   ],
   "source": [
    "result2 = clean_text(crude_article)\n",
    "print(set(result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python369jvsc74a57bd0a8383eef294e6eb532b9a275f580f77018a4c5ddf6bd4ca154421d62e44b7362",
   "display_name": "Python 3.6.9 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}